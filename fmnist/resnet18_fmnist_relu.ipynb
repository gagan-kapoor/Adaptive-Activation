{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPYetKwrGuUM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b0cf91a-4488-486b-9a83-f834fe4d380d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras.layers import (\n",
        "    Input,\n",
        "    Add,\n",
        "    Dense,\n",
        "    Activation,\n",
        "    ZeroPadding2D,\n",
        "    BatchNormalization,\n",
        "    Flatten,\n",
        "    Conv2D,\n",
        "    AveragePooling2D,\n",
        "    MaxPooling2D,\n",
        ")\n",
        "from keras.models import Model\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import layers\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import json\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train),(X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0],28,28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0],28,28,1)"
      ],
      "metadata": {
        "id": "a5B2MzYUX2Xc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a144c3d9-948e-49a2-c47e-41f5d948cd57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet18:\n",
        "  def __init__(self, num_classes = 10, input_shape = (None, None, 3), **kwargs):\n",
        "    self.num_classes = num_classes\n",
        "    self.input_shape = input_shape\n",
        "\n",
        "  def identity_block18(self, x, filter):\n",
        "\n",
        "    x_skip = x\n",
        "\n",
        "    x = keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
        "    x = keras.layers.BatchNormalization(axis=3)(x)\n",
        "    x = layers.Lambda( lambda x : tf.where(x > 0.0, x,0))(x)\n",
        "    x = keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
        "    x = keras.layers.BatchNormalization(axis=3)(x)\n",
        "\n",
        "    x = keras.layers.Add()([x, x_skip])\n",
        "    x = layers.Lambda( lambda x : tf.where(x > 0.0, x,0))(x)\n",
        "    return x\n",
        "\n",
        "  def convolutional_block18(self, x, filter):\n",
        "\n",
        "    x_skip = x\n",
        "\n",
        "    x = keras.layers.Conv2D(filter, (3,3), padding = 'same', strides = (2,2))(x)\n",
        "    x = keras.layers.BatchNormalization(axis=3)(x)\n",
        "    x = layers.Lambda( lambda x : tf.where(x > 0.0, x,0))(x)\n",
        "    x = keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
        "    x = keras.layers.BatchNormalization(axis=3)(x)\n",
        "\n",
        "    x_skip = keras.layers.Conv2D(filter, (1,1), strides = (2,2))(x_skip)\n",
        "\n",
        "    x = keras.layers.Add()([x, x_skip])\n",
        "    x = layers.Lambda( lambda x : tf.where(x > 0.0, x,0))(x)\n",
        "    return x\n",
        "\n",
        "  def build(self, **kwargs):\n",
        "\n",
        "    x_input = Input(self.input_shape)\n",
        "    x = ZeroPadding2D((3, 3))(x_input)\n",
        "\n",
        "\n",
        "    x = Conv2D(64, kernel_size=7, strides=2, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = layers.Lambda( lambda x : tf.where(x > 0.0, x,0))(x)\n",
        "    x = keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
        "\n",
        "\n",
        "    name = \"ResNet18\"\n",
        "    block_layers = [2, 2, 2, 2]\n",
        "    filter_size = 64\n",
        "\n",
        "\n",
        "    for i in range(4):\n",
        "        if i == 0:\n",
        "            for j in range(block_layers[i]):\n",
        "                x = self.identity_block18(x, filter_size)\n",
        "        else:\n",
        "            filter_size = filter_size*2\n",
        "            x = self.convolutional_block18(x, filter_size )\n",
        "            for j in range(block_layers[i] - 1):\n",
        "                x = self.identity_block18(x, filter_size)\n",
        "\n",
        "    x = AveragePooling2D((2,2), padding = 'same')(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(self.num_classes, activation = 'softmax')(x)\n",
        "    model = Model(inputs = x_input, outputs = x, name = name)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "uxSfTt-nV6Fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rn = ResNet18(input_shape=(28, 28, 1))\n",
        "model = rn.build()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "qH4RnmUHX6Pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=\"Adam\",\n",
        "\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "\n",
        "    metrics=[\"sparse_categorical_accuracy\"],\n",
        ")\n",
        "\n",
        "learning = model.fit(\n",
        "    X_train, y_train, validation_data=(X_test, y_test), epochs=30, verbose=1\n",
        ")\n",
        "\n",
        "loss_train = learning.history[\"loss\"]\n",
        "\n",
        "loss_val = learning.history[\"val_loss\"]\n",
        "\n",
        "acc_train = learning.history[\"sparse_categorical_accuracy\"]\n",
        "\n",
        "acc_val = learning.history[\"val_sparse_categorical_accuracy\"]\n",
        "\n",
        "y_pred = [np.argmax(arr) for arr in model.predict(X_test)]\n",
        "\n",
        "prf_score = precision_recall_fscore_support(y_test, y_pred, average=\"weighted\")\n",
        "\n",
        "score = model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "7ExKZIO_YP9p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2316a585-54d6-4229-a2a8-807a43506d8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1875/1875 [==============================] - 67s 26ms/step - loss: 0.4394 - sparse_categorical_accuracy: 0.8400 - val_loss: 0.4232 - val_sparse_categorical_accuracy: 0.8596\n",
            "Epoch 2/30\n",
            "1875/1875 [==============================] - 46s 25ms/step - loss: 0.3016 - sparse_categorical_accuracy: 0.8895 - val_loss: 0.3311 - val_sparse_categorical_accuracy: 0.8773\n",
            "Epoch 3/30\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.2698 - sparse_categorical_accuracy: 0.9006 - val_loss: 0.2962 - val_sparse_categorical_accuracy: 0.8907\n",
            "Epoch 4/30\n",
            "1875/1875 [==============================] - 44s 23ms/step - loss: 0.2410 - sparse_categorical_accuracy: 0.9107 - val_loss: 0.3046 - val_sparse_categorical_accuracy: 0.8895\n",
            "Epoch 5/30\n",
            "1875/1875 [==============================] - 44s 24ms/step - loss: 0.2122 - sparse_categorical_accuracy: 0.9213 - val_loss: 0.2475 - val_sparse_categorical_accuracy: 0.9107\n",
            "Epoch 6/30\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.1963 - sparse_categorical_accuracy: 0.9273 - val_loss: 0.2537 - val_sparse_categorical_accuracy: 0.9067\n",
            "Epoch 7/30\n",
            "1875/1875 [==============================] - 49s 26ms/step - loss: 0.1774 - sparse_categorical_accuracy: 0.9334 - val_loss: 0.2518 - val_sparse_categorical_accuracy: 0.9099\n",
            "Epoch 8/30\n",
            "1875/1875 [==============================] - 44s 23ms/step - loss: 0.1573 - sparse_categorical_accuracy: 0.9409 - val_loss: 0.2473 - val_sparse_categorical_accuracy: 0.9133\n",
            "Epoch 9/30\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.1402 - sparse_categorical_accuracy: 0.9471 - val_loss: 0.2525 - val_sparse_categorical_accuracy: 0.9134\n",
            "Epoch 10/30\n",
            "1875/1875 [==============================] - 44s 23ms/step - loss: 0.1261 - sparse_categorical_accuracy: 0.9528 - val_loss: 0.3083 - val_sparse_categorical_accuracy: 0.9079\n",
            "Epoch 11/30\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.1208 - sparse_categorical_accuracy: 0.9548 - val_loss: 0.2653 - val_sparse_categorical_accuracy: 0.9157\n",
            "Epoch 12/30\n",
            "1875/1875 [==============================] - 44s 24ms/step - loss: 0.0996 - sparse_categorical_accuracy: 0.9617 - val_loss: 0.2735 - val_sparse_categorical_accuracy: 0.9181\n",
            "Epoch 13/30\n",
            "1875/1875 [==============================] - 44s 23ms/step - loss: 0.0889 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.3700 - val_sparse_categorical_accuracy: 0.8993\n",
            "Epoch 14/30\n",
            "1875/1875 [==============================] - 44s 24ms/step - loss: 0.0907 - sparse_categorical_accuracy: 0.9678 - val_loss: 0.2774 - val_sparse_categorical_accuracy: 0.9190\n",
            "Epoch 15/30\n",
            "1875/1875 [==============================] - 44s 24ms/step - loss: 0.0694 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.2934 - val_sparse_categorical_accuracy: 0.9202\n",
            "Epoch 16/30\n",
            "1875/1875 [==============================] - 43s 23ms/step - loss: 0.0646 - sparse_categorical_accuracy: 0.9755 - val_loss: 0.3420 - val_sparse_categorical_accuracy: 0.9161\n",
            "Epoch 17/30\n",
            "1875/1875 [==============================] - 46s 24ms/step - loss: 0.0559 - sparse_categorical_accuracy: 0.9785 - val_loss: 0.3457 - val_sparse_categorical_accuracy: 0.9155\n",
            "Epoch 18/30\n",
            "1875/1875 [==============================] - 46s 25ms/step - loss: 0.0545 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.3741 - val_sparse_categorical_accuracy: 0.9129\n",
            "Epoch 19/30\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.0478 - sparse_categorical_accuracy: 0.9819 - val_loss: 0.3836 - val_sparse_categorical_accuracy: 0.9177\n",
            "Epoch 20/30\n",
            "1875/1875 [==============================] - 48s 26ms/step - loss: 0.0437 - sparse_categorical_accuracy: 0.9840 - val_loss: 0.3521 - val_sparse_categorical_accuracy: 0.9213\n",
            "Epoch 21/30\n",
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0400 - sparse_categorical_accuracy: 0.9852 - val_loss: 0.3956 - val_sparse_categorical_accuracy: 0.9220\n",
            "Epoch 22/30\n",
            "1875/1875 [==============================] - 44s 24ms/step - loss: 0.0350 - sparse_categorical_accuracy: 0.9875 - val_loss: 0.4287 - val_sparse_categorical_accuracy: 0.9186\n",
            "Epoch 23/30\n",
            "1875/1875 [==============================] - 44s 23ms/step - loss: 0.0361 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.4298 - val_sparse_categorical_accuracy: 0.9167\n",
            "Epoch 24/30\n",
            "1875/1875 [==============================] - 44s 24ms/step - loss: 0.0320 - sparse_categorical_accuracy: 0.9880 - val_loss: 0.4093 - val_sparse_categorical_accuracy: 0.9181\n",
            "Epoch 25/30\n",
            "1875/1875 [==============================] - 44s 23ms/step - loss: 0.0314 - sparse_categorical_accuracy: 0.9887 - val_loss: 0.4277 - val_sparse_categorical_accuracy: 0.9193\n",
            "Epoch 26/30\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.0289 - sparse_categorical_accuracy: 0.9895 - val_loss: 0.4829 - val_sparse_categorical_accuracy: 0.9154\n",
            "Epoch 27/30\n",
            "1875/1875 [==============================] - 44s 24ms/step - loss: 0.0308 - sparse_categorical_accuracy: 0.9895 - val_loss: 0.4264 - val_sparse_categorical_accuracy: 0.9170\n",
            "Epoch 28/30\n",
            "1875/1875 [==============================] - 44s 23ms/step - loss: 0.0238 - sparse_categorical_accuracy: 0.9914 - val_loss: 0.4751 - val_sparse_categorical_accuracy: 0.9145\n",
            "Epoch 29/30\n",
            "1875/1875 [==============================] - 43s 23ms/step - loss: 0.0265 - sparse_categorical_accuracy: 0.9910 - val_loss: 0.4903 - val_sparse_categorical_accuracy: 0.9157\n",
            "Epoch 30/30\n",
            "1875/1875 [==============================] - 44s 23ms/step - loss: 0.0236 - sparse_categorical_accuracy: 0.9917 - val_loss: 0.4504 - val_sparse_categorical_accuracy: 0.9147\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.4504 - sparse_categorical_accuracy: 0.9147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "performance = {\n",
        "    'loss_train': loss_train,\n",
        "    'loss_val': loss_val,\n",
        "    'acc_train': acc_train,\n",
        "    'acc_val': acc_val,\n",
        "    'prf_score': prf_score,\n",
        "    'score': score\n",
        "}\n",
        "\n",
        "performance_file_path = '/content/drive/My Drive/Colab Notebooks/relu_on_fmnist_performance.json'\n",
        "\n",
        "with open(performance_file_path, 'w') as f:\n",
        "    json.dump(performance, f)\n",
        "\n",
        "print(\"performance saved to:\", performance_file_path)"
      ],
      "metadata": {
        "id": "aua1gG8mNWIb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bbeb83e-5c8e-4ef5-dd2e-026eb20e2125"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "performance saved to: /content/drive/My Drive/Colab Notebooks/relu_on_fmnist_performance.json\n"
          ]
        }
      ]
    }
  ]
}