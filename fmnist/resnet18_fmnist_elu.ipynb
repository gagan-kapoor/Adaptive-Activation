{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPYetKwrGuUM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df5975f4-6959-4ada-e0a7-ce041abdcc1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras.layers import (\n",
        "    Input,\n",
        "    Add,\n",
        "    Dense,\n",
        "    Activation,\n",
        "    ZeroPadding2D,\n",
        "    BatchNormalization,\n",
        "    Flatten,\n",
        "    Conv2D,\n",
        "    AveragePooling2D,\n",
        "    MaxPooling2D,\n",
        ")\n",
        "from keras.models import Model\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import layers\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import json\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train),(X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0],28,28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0],28,28,1)"
      ],
      "metadata": {
        "id": "a5B2MzYUX2Xc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "667aad10-4eb5-4e0f-a5b0-0e794c15ea0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet18:\n",
        "  def __init__(self, num_classes = 10, input_shape = (None, None, 3), **kwargs):\n",
        "    self.num_classes = num_classes\n",
        "    self.input_shape = input_shape\n",
        "\n",
        "  def identity_block18(self, x, filter):\n",
        "\n",
        "    x_skip = x\n",
        "\n",
        "    x = keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
        "    x = keras.layers.BatchNormalization(axis=3)(x)\n",
        "    x = layers.Lambda(lambda x: tf.keras.activations.elu(x))(x)\n",
        "\n",
        "    x = keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
        "    x = keras.layers.BatchNormalization(axis=3)(x)\n",
        "\n",
        "    x = keras.layers.Add()([x, x_skip])\n",
        "    x = layers.Lambda(lambda x: tf.keras.activations.elu(x))(x)\n",
        "    return x\n",
        "\n",
        "  def convolutional_block18(self, x, filter):\n",
        "\n",
        "    x_skip = x\n",
        "\n",
        "    x = keras.layers.Conv2D(filter, (3,3), padding = 'same', strides = (2,2))(x)\n",
        "    x = keras.layers.BatchNormalization(axis=3)(x)\n",
        "    x = layers.Lambda(lambda x: tf.keras.activations.elu(x))(x)\n",
        "\n",
        "    x = keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
        "    x = keras.layers.BatchNormalization(axis=3)(x)\n",
        "\n",
        "    x_skip = keras.layers.Conv2D(filter, (1,1), strides = (2,2))(x_skip)\n",
        "\n",
        "    x = keras.layers.Add()([x, x_skip])\n",
        "    x = layers.Lambda(lambda x: tf.keras.activations.elu(x))(x)\n",
        "    return x\n",
        "\n",
        "  def build(self, **kwargs):\n",
        "\n",
        "    x_input = Input(self.input_shape)\n",
        "    x = ZeroPadding2D((3, 3))(x_input)\n",
        "\n",
        "\n",
        "    x = Conv2D(64, kernel_size=7, strides=2, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = layers.Lambda(lambda x: tf.keras.activations.elu(x))(x)\n",
        "    x = keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
        "\n",
        "\n",
        "    name = \"ResNet18\"\n",
        "    block_layers = [2, 2, 2, 2]\n",
        "    filter_size = 64\n",
        "\n",
        "\n",
        "    for i in range(4):\n",
        "        if i == 0:\n",
        "            for j in range(block_layers[i]):\n",
        "                x = self.identity_block18(x, filter_size)\n",
        "        else:\n",
        "            filter_size = filter_size*2\n",
        "            x = self.convolutional_block18(x, filter_size )\n",
        "            for j in range(block_layers[i] - 1):\n",
        "                x = self.identity_block18(x, filter_size)\n",
        "\n",
        "    x = AveragePooling2D((2,2), padding = 'same')(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(self.num_classes, activation = 'softmax')(x)\n",
        "    model = Model(inputs = x_input, outputs = x, name = name)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "uxSfTt-nV6Fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rn = ResNet18(input_shape=(28, 28, 1))\n",
        "model = rn.build()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "qH4RnmUHX6Pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=\"Adam\",\n",
        "\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "\n",
        "    metrics=[\"sparse_categorical_accuracy\"],\n",
        ")\n",
        "\n",
        "learning = model.fit(\n",
        "    X_train, y_train, validation_data=(X_test, y_test), epochs=30, verbose=1\n",
        ")\n",
        "\n",
        "loss_train = learning.history[\"loss\"]\n",
        "\n",
        "loss_val = learning.history[\"val_loss\"]\n",
        "\n",
        "acc_train = learning.history[\"sparse_categorical_accuracy\"]\n",
        "\n",
        "acc_val = learning.history[\"val_sparse_categorical_accuracy\"]\n",
        "\n",
        "y_pred = [np.argmax(arr) for arr in model.predict(X_test)]\n",
        "\n",
        "prf_score = precision_recall_fscore_support(y_test, y_pred, average=\"weighted\")\n",
        "\n",
        "score = model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "7ExKZIO_YP9p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a89b560-73cf-49d8-acfe-b1b646dda560"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1875/1875 [==============================] - 65s 27ms/step - loss: 0.4293 - sparse_categorical_accuracy: 0.8438 - val_loss: 0.3756 - val_sparse_categorical_accuracy: 0.8647\n",
            "Epoch 2/30\n",
            "1875/1875 [==============================] - 41s 22ms/step - loss: 0.2988 - sparse_categorical_accuracy: 0.8896 - val_loss: 0.2963 - val_sparse_categorical_accuracy: 0.8887\n",
            "Epoch 3/30\n",
            "1875/1875 [==============================] - 42s 23ms/step - loss: 0.2660 - sparse_categorical_accuracy: 0.9013 - val_loss: 0.2771 - val_sparse_categorical_accuracy: 0.8972\n",
            "Epoch 4/30\n",
            "1875/1875 [==============================] - 41s 22ms/step - loss: 0.2398 - sparse_categorical_accuracy: 0.9103 - val_loss: 0.3103 - val_sparse_categorical_accuracy: 0.8852\n",
            "Epoch 5/30\n",
            "1875/1875 [==============================] - 42s 22ms/step - loss: 0.2195 - sparse_categorical_accuracy: 0.9174 - val_loss: 0.2612 - val_sparse_categorical_accuracy: 0.9037\n",
            "Epoch 6/30\n",
            "1875/1875 [==============================] - 42s 22ms/step - loss: 0.1994 - sparse_categorical_accuracy: 0.9259 - val_loss: 0.2691 - val_sparse_categorical_accuracy: 0.9058\n",
            "Epoch 7/30\n",
            "1875/1875 [==============================] - 42s 22ms/step - loss: 0.1833 - sparse_categorical_accuracy: 0.9315 - val_loss: 0.2601 - val_sparse_categorical_accuracy: 0.9106\n",
            "Epoch 8/30\n",
            "1875/1875 [==============================] - 41s 22ms/step - loss: 0.1681 - sparse_categorical_accuracy: 0.9363 - val_loss: 0.2574 - val_sparse_categorical_accuracy: 0.9137\n",
            "Epoch 9/30\n",
            "1875/1875 [==============================] - 42s 22ms/step - loss: 0.1499 - sparse_categorical_accuracy: 0.9434 - val_loss: 0.2603 - val_sparse_categorical_accuracy: 0.9138\n",
            "Epoch 10/30\n",
            "1875/1875 [==============================] - 42s 22ms/step - loss: 0.1369 - sparse_categorical_accuracy: 0.9474 - val_loss: 0.2822 - val_sparse_categorical_accuracy: 0.9135\n",
            "Epoch 11/30\n",
            "1875/1875 [==============================] - 42s 23ms/step - loss: 0.1225 - sparse_categorical_accuracy: 0.9537 - val_loss: 0.2865 - val_sparse_categorical_accuracy: 0.9062\n",
            "Epoch 12/30\n",
            "1875/1875 [==============================] - 43s 23ms/step - loss: 0.1113 - sparse_categorical_accuracy: 0.9574 - val_loss: 0.2707 - val_sparse_categorical_accuracy: 0.9187\n",
            "Epoch 13/30\n",
            "1875/1875 [==============================] - 43s 23ms/step - loss: 0.1032 - sparse_categorical_accuracy: 0.9606 - val_loss: 0.3022 - val_sparse_categorical_accuracy: 0.9135\n",
            "Epoch 14/30\n",
            "1875/1875 [==============================] - 43s 23ms/step - loss: 0.0903 - sparse_categorical_accuracy: 0.9657 - val_loss: 0.2907 - val_sparse_categorical_accuracy: 0.9182\n",
            "Epoch 15/30\n",
            "1875/1875 [==============================] - 43s 23ms/step - loss: 0.0848 - sparse_categorical_accuracy: 0.9676 - val_loss: 0.2939 - val_sparse_categorical_accuracy: 0.9203\n",
            "Epoch 16/30\n",
            "1875/1875 [==============================] - 42s 23ms/step - loss: 0.0746 - sparse_categorical_accuracy: 0.9714 - val_loss: 0.3978 - val_sparse_categorical_accuracy: 0.9068\n",
            "Epoch 17/30\n",
            "1875/1875 [==============================] - 42s 22ms/step - loss: 0.0682 - sparse_categorical_accuracy: 0.9739 - val_loss: 0.3672 - val_sparse_categorical_accuracy: 0.9115\n",
            "Epoch 18/30\n",
            "1875/1875 [==============================] - 42s 22ms/step - loss: 0.0609 - sparse_categorical_accuracy: 0.9764 - val_loss: 0.3780 - val_sparse_categorical_accuracy: 0.9162\n",
            "Epoch 19/30\n",
            "1875/1875 [==============================] - 42s 22ms/step - loss: 0.0586 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.4330 - val_sparse_categorical_accuracy: 0.9140\n",
            "Epoch 20/30\n",
            "1875/1875 [==============================] - 41s 22ms/step - loss: 0.0531 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.3620 - val_sparse_categorical_accuracy: 0.9167\n",
            "Epoch 21/30\n",
            "1875/1875 [==============================] - 41s 22ms/step - loss: 0.0508 - sparse_categorical_accuracy: 0.9810 - val_loss: 0.3897 - val_sparse_categorical_accuracy: 0.9177\n",
            "Epoch 22/30\n",
            "1875/1875 [==============================] - 42s 22ms/step - loss: 0.0450 - sparse_categorical_accuracy: 0.9834 - val_loss: 0.4577 - val_sparse_categorical_accuracy: 0.9066\n",
            "Epoch 23/30\n",
            "1875/1875 [==============================] - 42s 22ms/step - loss: 0.0419 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.4846 - val_sparse_categorical_accuracy: 0.9060\n",
            "Epoch 24/30\n",
            "1875/1875 [==============================] - 42s 22ms/step - loss: 0.0429 - sparse_categorical_accuracy: 0.9840 - val_loss: 0.4501 - val_sparse_categorical_accuracy: 0.9177\n",
            "Epoch 25/30\n",
            "1875/1875 [==============================] - 42s 22ms/step - loss: 0.0359 - sparse_categorical_accuracy: 0.9867 - val_loss: 0.4627 - val_sparse_categorical_accuracy: 0.9212\n",
            "Epoch 26/30\n",
            "1875/1875 [==============================] - 41s 22ms/step - loss: 0.0382 - sparse_categorical_accuracy: 0.9863 - val_loss: 0.4685 - val_sparse_categorical_accuracy: 0.9165\n",
            "Epoch 27/30\n",
            "1875/1875 [==============================] - 41s 22ms/step - loss: 0.0335 - sparse_categorical_accuracy: 0.9878 - val_loss: 0.5226 - val_sparse_categorical_accuracy: 0.9181\n",
            "Epoch 28/30\n",
            "1875/1875 [==============================] - 41s 22ms/step - loss: 0.0324 - sparse_categorical_accuracy: 0.9883 - val_loss: 0.5100 - val_sparse_categorical_accuracy: 0.9132\n",
            "Epoch 29/30\n",
            "1875/1875 [==============================] - 41s 22ms/step - loss: 0.0323 - sparse_categorical_accuracy: 0.9885 - val_loss: 0.4627 - val_sparse_categorical_accuracy: 0.9155\n",
            "Epoch 30/30\n",
            "1875/1875 [==============================] - 41s 22ms/step - loss: 0.0301 - sparse_categorical_accuracy: 0.9893 - val_loss: 0.4630 - val_sparse_categorical_accuracy: 0.9160\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.4630 - sparse_categorical_accuracy: 0.9160\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "performance = {\n",
        "    'loss_train': loss_train,\n",
        "    'loss_val': loss_val,\n",
        "    'acc_train': acc_train,\n",
        "    'acc_val': acc_val,\n",
        "    'prf_score': prf_score,\n",
        "    'score': score\n",
        "}\n",
        "\n",
        "performance_file_path = '/content/drive/My Drive/Colab Notebooks/elu_on_fmnist_performance.json'\n",
        "\n",
        "with open(performance_file_path, 'w') as f:\n",
        "    json.dump(performance, f)\n",
        "\n",
        "print(\"performance saved to:\", performance_file_path)"
      ],
      "metadata": {
        "id": "aua1gG8mNWIb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d877403-241c-47ad-ea87-c9f84dc75819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "performance saved to: /content/drive/My Drive/Colab Notebooks/elu_on_fmnist_performance.json\n"
          ]
        }
      ]
    }
  ]
}